{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc7bb93c-a53d-4ae7-8df7-7859d21b8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "430a763d-fdf3-46ba-9db6-9ee179dcfc2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "#import iris data\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(iris.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a2a7558-f0a1-44b4-baf3-5cb88908b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class for model creation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class CustomLogisticRegressionModel:\n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def train(self, X_train=None, y_train=None):\n",
    "        if X_train is not None and y_train is not None:\n",
    "            self.X = X_train\n",
    "            self.y = y_train\n",
    "        self.model.fit(self.X, self.y)\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcc11eb8-46f6-4490-bd3b-87c1f1a8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aadya/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#create original model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "original_model = CustomLogisticRegressionModel(X_train, y_train)\n",
    "original_model.train()\n",
    "\n",
    "# Evaluate the model with testing data\n",
    "test_accuracy = original_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Testing accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d34948d7-e2b8-4f34-b58d-6f08e857a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aadya/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#create unlearned model\n",
    "index_unlearned = np.random.randint(0, len(X))\n",
    "\n",
    "X_unlearned = X.drop(index=index_unlearned)\n",
    "y_unlearned = y.drop(index=index_unlearned)\n",
    "\n",
    "X_train_unlearned, X_test_unlearned, y_train_unlearned, y_test_unlearned = train_test_split(X_unlearned, y_unlearned, test_size=0.2, random_state=42)\n",
    "\n",
    "unlearned_model = CustomLogisticRegressionModel(X_train_unlearned, y_train_unlearned)\n",
    "unlearned_model.train()\n",
    "\n",
    "# Evaluate the model with testing data\n",
    "test_accuracy_unlearned = unlearned_model.evaluate(X_test_unlearned, y_test_unlearned)\n",
    "\n",
    "print(f\"Testing accuracy: {test_accuracy_unlearned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fca95-98fb-4bdb-b575-6c0664207542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

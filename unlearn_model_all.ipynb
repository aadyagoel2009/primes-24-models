{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc7bb93c-a53d-4ae7-8df7-7859d21b8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "430a763d-fdf3-46ba-9db6-9ee179dcfc2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1    2    3\n",
      "0      6.3  2.7  1.4  0.3\n",
      "1      6.5  2.7  6.1  1.9\n",
      "2      5.9  3.6  1.1  0.3\n",
      "3      5.4  2.6  1.1  1.4\n",
      "4      6.5  3.2  1.4  1.8\n",
      "...    ...  ...  ...  ...\n",
      "49731  6.3  3.3  5.5  2.4\n",
      "49732  5.7  3.1  3.9  1.9\n",
      "49733  5.7  2.7  0.9  1.6\n",
      "49734  4.8  3.0  3.3  1.4\n",
      "49735  5.6  2.7  4.3  1.3\n",
      "\n",
      "[49736 rows x 4 columns]\n",
      "                   4\n",
      "0          I. setosa\n",
      "1       I. virginica\n",
      "2          I. setosa\n",
      "3      I. versicolor\n",
      "4      I. versicolor\n",
      "...              ...\n",
      "49731   I. virginica\n",
      "49732  I. versicolor\n",
      "49733      I. setosa\n",
      "49734      I. setosa\n",
      "49735  I. versicolor\n",
      "\n",
      "[49736 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#import iris data\n",
    "#from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "#iris = fetch_ucirepo(id=53) \n",
    "iris = pd.read_csv('Synthetic_IRIS_Dataset_Ray.csv', header=None, skiprows=6)\n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "#X = iris.data.features \n",
    "#y = iris.data.targets \n",
    "X = iris.iloc[:, 0:4]\n",
    "y = iris.iloc[:, 4:5]\n",
    "print(X)\n",
    "print(y)\n",
    "  \n",
    "# metadata \n",
    "#print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(iris.variables) \n",
    "\n",
    "num_groups = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a2a7558-f0a1-44b4-baf3-5cb88908b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class for model creation\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class CustomModel:\n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.m = num_groups \n",
    "        subsize = int(X.shape[0] / self.m)\n",
    "        self.model, self.X, self.y = [], [], []\n",
    "        for i in range(self.m):\n",
    "            self.model.append(MLPClassifier(hidden_layer_sizes=(15,10,5), max_iter=300,activation = 'relu',solver='adam',random_state=1))\n",
    "            self.X.append(X[i*subsize:(i+1)*subsize].values)\n",
    "            self.y.append(y[i*subsize:(i+1)*subsize].values)\n",
    "\n",
    "    def dropData(self, groupid, cnt_Xy):\n",
    "        #self.X[groupid] = self.X[groupid].drop(index=i)\n",
    "        #self.y[groupid] = self.y[groupid].drop(index=i)\n",
    "        #del self.X[groupid][1:cnt_Xy]\n",
    "        #del self.y[groupid][1:cnt_Xy]\n",
    "        self.X[groupid] = self.X[groupid][cnt_Xy+1:]\n",
    "        self.y[groupid] = self.y[groupid][cnt_Xy+1:]\n",
    "\n",
    "    def train(self, X_train=None, y_train=None):\n",
    "        #if X_train is not None and y_train is not None:\n",
    "        #    self.X = X_train\n",
    "        #    self.y = y_train\n",
    "        for i in range(self.m):\n",
    "            self.model[i].fit(self.X[i], self.y[i])\n",
    "\n",
    "    def train_one_group(self, groupid, X_train=None, y_train=None):\n",
    "        #if X_train is not None and y_train is not None:\n",
    "        #    self.X = X_train\n",
    "        #    self.y = y_train\n",
    "        self.model[groupid].fit(self.X[groupid], self.y[groupid])\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        pdics = []\n",
    "        for i in range(self.m): #self.m\n",
    "            y_pred = self.model[i].predict(X_test)\n",
    "            if i == 0:\n",
    "                for pred in y_pred:\n",
    "                    pdic = dict()\n",
    "                    pdic[pred] = 1\n",
    "                    pdics.append(pdic)\n",
    "                \n",
    "            else:\n",
    "                for j in range(y_pred.shape[0]):\n",
    "                    if y_pred[j] in pdics[j]:\n",
    "                        pdics[j][y_pred[j]] += 1\n",
    "                    else:\n",
    "                        pdics[j][y_pred[j]] = 1\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            mcount = pdics[i][y_pred[i]]\n",
    "            for key, value in pdics[i].items():\n",
    "                if value > mcount:\n",
    "                    y_pred[i] = key\n",
    "                    mcount = value\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcc11eb8-46f6-4490-bd3b-87c1f1a8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8685162846803377\n"
     ]
    }
   ],
   "source": [
    "#create original model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "original_model = CustomModel(X_train, y_train)\n",
    "original_model.train()\n",
    "\n",
    "# Evaluate the model with testing data\n",
    "test_accuracy = original_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Testing accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1ad64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d34948d7-e2b8-4f34-b58d-6f08e857a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8677121029352634\n"
     ]
    }
   ],
   "source": [
    "#create unlearned model\n",
    "unlearned_model = CustomModel(X_train, y_train)\n",
    "cnt_drop_per_group = int(X.shape[0] / num_groups * 0.1) \n",
    "\n",
    "#test1. drop data in multiple groups\n",
    "for i in range(10):\n",
    "    unlearned_model.dropData( i, cnt_drop_per_group)\n",
    "\n",
    "unlearned_model.train()\n",
    "\n",
    "# Evaluate the model with testing data\n",
    "test_accuracy_unlearned = unlearned_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Testing accuracy: {test_accuracy_unlearned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd8fca95-98fb-4bdb-b575-6c0664207542",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by MLPClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#test2. drop the same amount of data only from group 1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m unlearned_model\u001b[38;5;241m.\u001b[39mdropData( \u001b[38;5;241m1\u001b[39m, cnt_drop_per_group\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43munlearned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate the model with testing data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m test_accuracy_unlearned \u001b[38;5;241m=\u001b[39m unlearned_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[52], line 36\u001b[0m, in \u001b[0;36mCustomModel.train_one_group\u001b[0;34m(self, groupid, X_train, y_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_one_group\u001b[39m(\u001b[38;5;28mself\u001b[39m, groupid, X_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#if X_train is not None and y_train is not None:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#    self.X = X_train\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#    self.y = y_train\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroupid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroupid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroupid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:749\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:437\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hidden_layer_sizes\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental\n\u001b[1;32m    435\u001b[0m )\n\u001b[0;32m--> 437\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1089\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, incremental, reset):\n\u001b[0;32m-> 1089\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1098\u001b[0m         y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Documents/adam/math/Courses/PRIMES_STEP/PRIMES2023-2024/PRIMES/dataset2/.conda/lib/python3.11/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by MLPClassifier."
     ]
    }
   ],
   "source": [
    "#test2. drop the same amount of data only from group 1&2\n",
    "unlearned_model.dropData( 1, cnt_drop_per_group*5)\n",
    "unlearned_model.dropData( 2, cnt_drop_per_group*5)\n",
    "unlearned_model.train_one_group(1)\n",
    "unlearned_model.train_one_group(2)\n",
    "\n",
    "# Evaluate the model with testing data\n",
    "test_accuracy_unlearned = unlearned_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Testing accuracy: {test_accuracy_unlearned}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
